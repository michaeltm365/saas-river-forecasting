{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we train LSTM models to predict dry (0) or wet (1) for a given HJ Andrews River Site on a given date.\n",
    "\n",
    "We use the following advanced techniques:\n",
    "- **Optuna** for hyperparameter optimization\n",
    "- **ADASYN** for handling class imbalance\n",
    "- **Permutation importance** for feature analysis\n",
    "- **Early stopping** to prevent overfitting\n",
    "\n",
    "At the bottom of the notebook, we provide a function for practitioners to run inference with our trained models for an inputted site-date combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score, precision_score,\n",
    "    recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "import optuna\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization.matplotlib import plot_contour\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load static variables and observations\n",
    "static_vars_df = pd.read_parquet('/Users/michaelmurphy/Desktop/usgs_data/static_vars.parquet')\n",
    "obs_df = pd.read_parquet('/Users/michaelmurphy/Desktop/usgs_data/obs.parquet')\n",
    "\n",
    "print('static_vars_df head:')\n",
    "print(static_vars_df.head())\n",
    "print('\\nobs_df head:')\n",
    "print(obs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot static vars (each variable as a column)\n",
    "static_wide = static_vars_df.pivot(index='NHDPlusID', columns='variable', values='value').reset_index()\n",
    "\n",
    "#Pivot obs_df (Date as rows, variable as columns)\n",
    "obs_wide = obs_df.pivot_table(index=['NHDPlusID', 'Date'], columns='variable', values='value').reset_index()\n",
    "\n",
    "#Merge static features into each site's obs\n",
    "merged_df = obs_wide.merge(static_wide, on='NHDPlusID', how='left')\n",
    "\n",
    "#Sort and forward-fill\n",
    "merged_df = merged_df.sort_values(['NHDPlusID', 'Date']).ffill()\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discretization: Convert continuous discharge into wet/dry\n",
    "DRY_THRESHOLD = 0.00014   # threshold for discharge\n",
    "\n",
    "#Create a new binary column from discharge\n",
    "merged_df[\"wetdry_discharge\"] = (merged_df[\"Discharge_CMS\"] >= DRY_THRESHOLD).astype(int)\n",
    "\n",
    "#Combine HOBO + discharge discretization\n",
    "merged_df[\"wetdry_final\"] = merged_df[\"HoboWetDry0.05\"]\n",
    "merged_df[\"wetdry_final\"] = merged_df[\"wetdry_final\"].fillna(merged_df[\"wetdry_discharge\"])\n",
    "\n",
    "print(\"Final combined wet/dry distribution:\")\n",
    "print(merged_df[\"wetdry_final\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick sites that have both classes (wet and dry)\n",
    "valid_obs = merged_df.dropna(subset=[\"wetdry_final\"])\n",
    "site_variation = valid_obs.groupby(\"NHDPlusID\")[\"wetdry_final\"].nunique()\n",
    "sites_with_both = site_variation[site_variation > 1].index.tolist()\n",
    "\n",
    "#Pick site with most valid observations\n",
    "site_counts = merged_df[merged_df[\"NHDPlusID\"].isin(sites_with_both)].groupby(\"NHDPlusID\")[\"wetdry_final\"].apply(lambda x: x.dropna().shape[0])\n",
    "best_site = site_counts.idxmax()\n",
    "print(f\"Using site {best_site} with {site_counts[best_site]} valid samples\")\n",
    "\n",
    "#Subset data for that site\n",
    "site_df = merged_df[merged_df[\"NHDPlusID\"] == best_site].dropna(subset=[\"wetdry_final\"]).sort_values(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill all NaNs\n",
    "df = site_df.copy()\n",
    "df = df.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
    "\n",
    "target_col = \"wetdry_final\"\n",
    "y_original = df[target_col].astype(int).values\n",
    "\n",
    "#Select numeric features only (remove date, ID, target)\n",
    "df_numeric = df.select_dtypes(include=[np.number]).drop(columns=[target_col], errors='ignore')\n",
    "\n",
    "#Scale features\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df_numeric)\n",
    "df_scaled = pd.DataFrame(scaled, columns=df_numeric.columns)\n",
    "\n",
    "#Add label back\n",
    "df_scaled_with_label = df_scaled.copy()\n",
    "df_scaled_with_label[target_col] = y_original\n",
    "\n",
    "print(\"df_scaled_with_label shape:\", df_scaled_with_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create sequences for LSTM (30-day window)\n",
    "def create_sequences(df, seq_len=30, target_col=\"wetdry_final\"):\n",
    "    X, y = [], []\n",
    "    values = df.drop(target_col, axis=1).values\n",
    "    labels = df[target_col].values\n",
    "    \n",
    "    for i in range(len(df) - seq_len):\n",
    "        seq = values[i:i+seq_len]\n",
    "        target = labels[i+seq_len]\n",
    "        \n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_len = 30\n",
    "X, y = create_sequences(df_scaled_with_label, seq_len=seq_len, target_col=target_col)\n",
    "\n",
    "print(\"NaNs in X:\", np.isnan(X).sum())\n",
    "print(\"NaNs in y:\", np.isnan(y).sum())\n",
    "print(f\"Generated {len(X)} sequences with seq_len={seq_len}\")\n",
    "print(\"Shapes:\", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN for Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply ADASYN to fix class imbalance\n",
    "n, T, d = X.shape\n",
    "\n",
    "#Flatten sequences: (n, T, d) -> (n, T*d)\n",
    "X_flat = X.reshape(n, T * d)\n",
    "\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_flat_res, y_res = adasyn.fit_resample(X_flat, y.astype(int))\n",
    "\n",
    "#Reshape back to (n_resampled, T, d)\n",
    "X_res = X_flat_res.reshape(-1, T, d)\n",
    "\n",
    "print(\"Original class counts:\", np.bincount(y.astype(int)))\n",
    "print(\"After ADASYN:\", np.bincount(y_res.astype(int)))\n",
    "print(\"Original shape:\", X.shape, \"Resampled shape:\", X_res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to tensors (use ADASYN output)\n",
    "X_tensor = torch.tensor(X_res, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_res.reshape(-1, 1), dtype=torch.float32)\n",
    "\n",
    "print(\"X_tensor:\", X_tensor.shape)\n",
    "print(\"y_tensor:\", y_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tensor, y_tensor, test_size=0.2, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optuna objective\n",
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 128)\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.0, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    epochs      = 7 # prev 7  # short tuning run\n",
    "    \n",
    "    model = LSTMModel(\n",
    "        input_size=X_tensor.shape[2],\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout\n",
    "    )\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Training\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            p = model(xb).squeeze().cpu().numpy()\n",
    "            preds.append(p)\n",
    "            actuals.append(yb.squeeze().cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds)\n",
    "    actuals = np.concatenate(actuals)\n",
    "    \n",
    "    if len(np.unique(actuals)) < 2:\n",
    "        return 1.0  # meaningless trial\n",
    "    \n",
    "    auc = roc_auc_score(actuals, preds)\n",
    "    return 1 - auc  # minimize (1 - AUC)\n",
    "\n",
    "#Run Optuna study\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=7) # prev 7\n",
    "\n",
    "print(\"\\nâœ… Best Hyperparameters:\")\n",
    "print(study.best_params)\n",
    "print(f\"Best Validation AUC: {1 - study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contour plot: lr vs dropout\n",
    "fig = plot_contour(\n",
    "    study,\n",
    "    params=[\"lr\", \"dropout\"]\n",
    ")\n",
    "plt.title(\"Contour Plot: lr vs dropout\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter importances\n",
    "fig = plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use best params from Optuna (update these with your results)\n",
    "best_params = study.best_params\n",
    "\n",
    "#Compute pos_weight for class balance\n",
    "pos = int(y_train.sum().item())\n",
    "neg = int((1 - y_train).sum().item())\n",
    "safe_pos_weight = 1.0  # mild weight\n",
    "pos_weight_tensor = torch.tensor([safe_pos_weight], dtype=torch.float32)\n",
    "\n",
    "print(\"safe_pos_weight =\", safe_pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define final model with best hyperparameters\n",
    "model = LSTMModel(\n",
    "    input_size=X_tensor.shape[2],\n",
    "    hidden_size=best_params['hidden_size'],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=best_params['batch_size'], shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val, y_val), batch_size=best_params['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with early stopping\n",
    "best_val_loss = float(\"inf\")\n",
    "best_state = None\n",
    "patience = 3\n",
    "wait = 0\n",
    "epochs = 15 # prev 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(xb)\n",
    "        logits = torch.nan_to_num(logits, nan=0.0, posinf=5.0, neginf=-5.0)\n",
    "        \n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Validation loss\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            logits = model(xb)\n",
    "            logits = torch.nan_to_num(logits, nan=0.0, posinf=5.0, neginf=-5.0)\n",
    "            val_loss += criterion(logits, yb).item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss={total_loss/len(train_loader):.4f} | Val Loss={val_loss/len(val_loader):.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_state = model.state_dict().copy()\n",
    "        wait = 0\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Loaded best model state.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions safely\n",
    "def get_probs(loader):\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            logits = model(xb)\n",
    "            logits = torch.nan_to_num(logits, nan=0.0)\n",
    "            \n",
    "            probs = torch.sigmoid(logits).squeeze().cpu().numpy()\n",
    "            probs = np.nan_to_num(probs, nan=0.0)\n",
    "            \n",
    "            preds.append(probs)\n",
    "            actuals.append(yb.squeeze().cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(preds), np.concatenate(actuals)\n",
    "\n",
    "train_probs, train_true = get_probs(train_loader)\n",
    "val_probs, val_true = get_probs(val_loader)\n",
    "\n",
    "#Sanitize all values\n",
    "train_probs = np.nan_to_num(train_probs, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "val_probs   = np.nan_to_num(val_probs, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "\n",
    "train_true = np.nan_to_num(train_true, nan=0.0)\n",
    "val_true   = np.nan_to_num(val_true, nan=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply threshold\n",
    "threshold = 0.5\n",
    "train_pred = (train_probs >= threshold).astype(int)\n",
    "val_pred   = (val_probs >= threshold).astype(int)\n",
    "\n",
    "#Compute metrics\n",
    "def compute_metrics(y_true, y_prob, y_pred):\n",
    "    cm   = confusion_matrix(y_true, y_pred)\n",
    "    acc  = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, y_pred)\n",
    "    auc  = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) > 1 else float('nan')\n",
    "    return cm, acc, prec, rec, f1, auc\n",
    "\n",
    "train_cm, train_acc, train_prec, train_rec, train_f1, train_auc = compute_metrics(train_true, train_probs, train_pred)\n",
    "val_cm, val_acc, val_prec, val_rec, val_f1, val_auc = compute_metrics(val_true, val_probs, val_pred)\n",
    "\n",
    "print(\"\\n================ TRAIN METRICS ================\")\n",
    "print(f\"Accuracy:  {train_acc:.4f}\")\n",
    "print(f\"Precision: {train_prec:.4f}\")\n",
    "print(f\"Recall:    {train_rec:.4f}\")\n",
    "print(f\"F1 Score:  {train_f1:.4f}\")\n",
    "print(f\"AUC:       {train_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", train_cm)\n",
    "\n",
    "print(\"\\n================ VAL METRICS ================\")\n",
    "print(f\"Accuracy:  {val_acc:.4f}\")\n",
    "print(f\"Precision: {val_prec:.4f}\")\n",
    "print(f\"Recall:    {val_rec:.4f}\")\n",
    "print(f\"F1 Score:  {val_f1:.4f}\")\n",
    "print(f\"AUC:       {val_auc:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", val_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrices\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(train_cm, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
    "ax[0].set_title(\"Train Confusion Matrix\")\n",
    "ax[0].set_xlabel('Predicted')\n",
    "ax[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(val_cm, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
    "ax[1].set_title(\"Validation Confusion Matrix\")\n",
    "ax[1].set_xlabel('Predicted')\n",
    "ax[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap\n",
    "numeric_df = df_scaled_with_label.select_dtypes(include=[np.number])\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(numeric_df.corr(), cmap='coolwarm', center=0, annot=False)\n",
    "plt.title(\"Correlation Heatmap of All Numeric Features\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with target\n",
    "corr_target = numeric_df.corr()[target_col].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(6, 10))\n",
    "sns.barplot(y=corr_target.index, x=corr_target.values, palette=\"viridis\")\n",
    "plt.title(\"Correlation of Features with Wet/Dry Target\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Permutation importance\n",
    "def perm_importance(model, X_val, y_val, n_repeats=5):\n",
    "    base_preds = torch.sigmoid(model(X_val)).detach().cpu().numpy()\n",
    "    base_f1 = f1_score(y_val, (base_preds > 0.5))\n",
    "    \n",
    "    importances = []\n",
    "    \n",
    "    for col in range(X_val.shape[2]):\n",
    "        f1_scores = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X_val.clone()\n",
    "            X_permuted[:, :, col] = X_val[:, :, col][torch.randperm(X_val.shape[0])]\n",
    "            perm_preds = torch.sigmoid(model(X_permuted)).detach().cpu().numpy()\n",
    "            f1_scores.append(f1_score(y_val, (perm_preds > 0.5)))\n",
    "        importances.append(base_f1 - np.mean(f1_scores))\n",
    "    \n",
    "    return np.array(importances)\n",
    "\n",
    "imps = perm_importance(model, X_val, val_true)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=np.arange(len(imps)), y=imps)\n",
    "plt.title(\"Permutation Importance per Feature Index\")\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Importance (F1 Drop)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discharge lagged features\n",
    "df_vis = site_df.copy()\n",
    "df_vis = df_vis.sort_values(\"Date\")\n",
    "\n",
    "df_vis[\"discharge_lag1\"] = df_vis[\"Discharge_CMS\"].shift(1)\n",
    "df_vis[\"discharge_lag7\"] = df_vis[\"Discharge_CMS\"].shift(7)\n",
    "df_vis[\"discharge_lag30\"] = df_vis[\"Discharge_CMS\"].shift(30)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.scatterplot(x=df_vis[\"discharge_lag1\"], y=df_vis[\"Discharge_CMS\"], s=10)\n",
    "plt.title(\"Discharge vs Lag-1\")\n",
    "plt.xlabel(\"Lag 1\")\n",
    "plt.ylabel(\"Current\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.scatterplot(x=df_vis[\"discharge_lag7\"], y=df_vis[\"Discharge_CMS\"], s=10)\n",
    "plt.title(\"Discharge vs Lag-7\")\n",
    "plt.xlabel(\"Lag 7\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.scatterplot(x=df_vis[\"discharge_lag30\"], y=df_vis[\"Discharge_CMS\"], s=10)\n",
    "plt.title(\"Discharge vs Lag-30\")\n",
    "plt.xlabel(\"Lag 30\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rolling wet/dry trend\n",
    "df_vis[\"rolling_wet\"] = df_vis[target_col].rolling(100).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_vis[\"Date\"], df_vis[\"rolling_wet\"])\n",
    "plt.title(\"Rolling % of Wet Days (Window=100)\")\n",
    "plt.ylabel(\"Pct Wet\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_site_date_lstm(model, scaler, site_df, seq_len, site_id, date, target_col=\"wetdry_final\"):\n",
    "    \"\"\"\n",
    "    Predict wet/dry status for a given site and date using LSTM.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : LSTMModel\n",
    "        Trained LSTM model\n",
    "    scaler : StandardScaler\n",
    "        Fitted scaler for feature normalization\n",
    "    site_df : pd.DataFrame\n",
    "        Complete dataset for the site with all features\n",
    "    seq_len : int\n",
    "        Sequence length used in training (e.g., 30)\n",
    "    site_id : str\n",
    "        Site identifier (e.g., \"55000900061097\")\n",
    "    date : str\n",
    "        Date in format \"YYYY-MM-DD\"\n",
    "    target_col : str\n",
    "        Target column name\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Prediction result with probability\n",
    "    \"\"\"\n",
    "    date = pd.to_datetime(date).date()\n",
    "    site_id = str(site_id)\n",
    "    \n",
    "    # Get site data\n",
    "    site_data = site_df[site_df[\"NHDPlusID\"] == site_id].sort_values(\"Date\")\n",
    "    \n",
    "    if site_data.empty:\n",
    "        return f\"No data found for Site {site_id}\"\n",
    "    \n",
    "    # Find the date index\n",
    "    date_idx = site_data[site_data[\"Date\"] == date].index\n",
    "    \n",
    "    if len(date_idx) == 0:\n",
    "        return f\"No data found for Site {site_id} on {date.date()}\"\n",
    "    \n",
    "    date_idx = date_idx[0]\n",
    "    date_pos = site_data.index.get_loc(date_idx)\n",
    "    \n",
    "    # Check if we have enough history\n",
    "    if date_pos < seq_len:\n",
    "        return f\"Not enough historical data (need {seq_len} days) for {date.date()}\"\n",
    "    \n",
    "    # Extract sequence\n",
    "    seq_data = site_data.iloc[date_pos - seq_len:date_pos]\n",
    "    \n",
    "    # Prepare features\n",
    "    df_numeric = seq_data.select_dtypes(include=[np.number]).drop(columns=[target_col], errors='ignore')\n",
    "    seq_scaled = scaler.transform(df_numeric)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    seq_tensor = torch.tensor(seq_scaled, dtype=torch.float32).unsqueeze(0)  # (1, seq_len, features)\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(seq_tensor)\n",
    "        prob = torch.sigmoid(logits).item()\n",
    "    \n",
    "    pred_class = 1 if prob >= 0.5 else 0\n",
    "    \n",
    "    return f\"Site {site_id} on {date}: {'DRY' if pred_class == 0 else 'WET'}, (P(wet)={prob:.4f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example inference\n",
    "# predict_site_date_lstm(\n",
    "#     model=model,\n",
    "#     scaler=scaler,\n",
    "#     site_df=merged_df,\n",
    "#     seq_len=30,\n",
    "#     site_id=best_site,\n",
    "#     date=\"2020-10-22\",\n",
    "#     target_col=\"wetdry_final\"\n",
    "# )\n",
    "\n",
    "predict_site_date_lstm(\n",
    "    model=model,\n",
    "    scaler=scaler,\n",
    "    site_df=merged_df,\n",
    "    seq_len=30,\n",
    "    site_id=\"55000900272714\",\n",
    "    date=\"2020-10-18\",\n",
    "    target_col=\"wetdry_final\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_id=\"55000900272714\"\n",
    "# date=\"2020-10-18\"\n",
    "date=\"2020-06-24\"\n",
    "\n",
    "site_df=merged_df\n",
    "\n",
    "date = pd.to_datetime(date).date()\n",
    "site_id = str(site_id)\n",
    "\n",
    "# Get site data\n",
    "site_data = site_df[site_df[\"NHDPlusID\"] == site_id].sort_values(\"Date\")\n",
    "\n",
    "# Find the date index\n",
    "date_idx = site_data[site_data[\"Date\"] == date].index\n",
    "\n",
    "print(date)\n",
    "\n",
    "print(site_data[\"Date\"].iloc[0])\n",
    "\n",
    "# date_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hbmv_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
